syntax = "proto3";

import "google/protobuf/timestamp.proto";

option java_package = "com.grammatek.simaromur.cache";
option java_multiple_files = true;

message PhonemeEntry {
    // phoneme symbols as generated by G2P
    string symbols = 1;
    // MD5sum of phoneme_text
    string md5 = 2;
}

// audio format used for the audio file
enum AudioFormat {
    INVALID_AUDIO_FMT = 0;
    AUDIO_FMT_PCM = 1;
    AUDIO_FMT_MP3 = 2;
    // TODO: what else ?
}

// sample rate used for audio file
enum SampleRate {
    INVALID_SAMPLE_RATE = 0;
    SAMPLE_RATE_11KHZ = 1;
    SAMPLE_RATE_16KHZ = 2;
    SAMPLE_RATE_22KHZ = 3;
    SAMPLE_RATE_44_1KHZ = 4;
    SAMPLE_RATE_48KHZ = 5;
}

// Describes the voice audio for a specific phoneme
message VoiceAudioDescription {
    AudioFormat format = 1;
    SampleRate rate = 2;

    // voice name used for generation of audio file
    string voice_name = 3;

    // voice version used for generation of audio file
    string voice_version = 4;

    // File path of the audio file
    // if empty: audio file hasn't been generated for this utterance item
    // the url should be unique for the voice_name/voice_version/phoneme text,
    // but reusable for multiple utterances,
    //      e.g. <parent-dir>/voiceName_voiceVersion/phoneme-md5sum.<format>
    string path = 5;

    // size of the file given in url in bytes on the filesystem
    uint32 file_size = 6;
}

// Utterance description
message Utterance {

    // version of the frontend pipeline
    string frontend_version = 1;

    // original raw text, this is the unique distinction point for a CacheItem
    string text = 2;

    // result of the normalization process
    string normalized = 3;

    // G2P can be made up of multiple entries dependent on e.g. sentence
    // splitting of the normalized text. The corresponding audio for the
    // whole utterance is also spread over multiple files and shall have the same
    // order as the phonemes.
    // Before there is no entry here, an audio file cannot be attached to a CacheItem
    repeated PhonemeEntry phonemes = 4;

    // MD5 sum of the text, this is for lookup optimization
    string text_md5sum = 5;
}

message AudioEntry {
    // Array of audio descriptors belonging to a CacheItem/Voice combination
    // The order of the parts corresponds to the order of the phonemes
    // in the corresponding utterance.
    //
    // If empty: no audio file yet generated. If the size
    // is less than the number of phonemes, then not all
    // audio files have been generated yet. The order in this list shall be the same
    // as the corresponding phoneme of the utterance.
    repeated VoiceAudioDescription audio_descriptors = 1;
}

message CacheItem {
    // the utterance, the text item is the unique distinction for a CacheItem
    Utterance utterance = 1;

    // maps voice:version to generated voice audio file(s)
    // The key should be constructed like: Voice name + ":" + Voice version
    //      example:
    //          "Alfur:1"
    // if map is empty: no audio file yet generated
    map<string, AudioEntry> voice_audio_entries = 2;

    // the unique id of this CacheItem, must not be empty
    string uuid = 3;

    // usage count of the cache element
    uint32 usage_count = 4;

    // Timestamp for last usage of this cache item
    google.protobuf.Timestamp timestamp = 5;
}

message UtteranceCache {
    // cache version, if major number changes, cache should be rebuilt
    string version = 1;

    // map CacheItem UUID to its CacheItem
    map<string, CacheItem> entries = 2;

    // Map MD5sum of raw text to to a CacheItem uuid. This is used for lookup optimization.
    // The map key is the same as in Utterance.text_md5sum.
    map<string, string> md5_entries = 3;
}
